{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Libraries\n",
    "\n",
    "#Dataframe and numerical library\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "#Machine Learming Model\n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/datasets/main/Leads.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/datasets/main/churn.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Lead Number','Prospect ID', 'Asymmetrique Activity Index','Asymmetrique Profile Index','Asymmetrique Activity Score','Asymmetrique Profile Score','Lead Quality','Tags','City','Lead Profile','What matters most to you in choosing a course','What is your current occupation','How did you hear about X Education','Specialization','Country'], axis=1, inplace=True)\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.fillna(0)\n",
    "#print(df.isnull().sum())\n",
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64','float64']\n",
    "catDF = df.select_dtypes(exclude=numerics)\n",
    "numDF = df.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(catDF.head())\n",
    "numDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all numeric columns\n",
    "numDF = pd.DataFrame(scaler.fit_transform(numDF.values), columns=numDF.columns, index=numDF.index)\n",
    "numDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target variable from the DF\n",
    "catDF.drop(['churn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all the categorical variables to dummy variables\n",
    "catDF = pd.get_dummies(catDF)\n",
    "catDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with the original data frame\n",
    "# Preparing the X variables\n",
    "X = pd.concat([catDF, numDF], axis=1)\n",
    "print(X.shape)\n",
    "# Preparing the Y variable\n",
    "Y = df['churn']\n",
    "# Tree models have trouble turning strings to float to labeling the target variable so there is a complete feature matrix\n",
    "Y = Y.replace(to_replace=['No','Yes'],value=[0,1])\n",
    "print(Y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Converting each of the columns to scaled version\n",
    "\n",
    "df['TotalVisits'] = rob_scaler.fit_transform(df['TotalVisits'].values.reshape(-1,1))\n",
    "df['Page Views Per Visit'] = rob_scaler.fit_transform(df['Page Views Per Visit'].values.reshape(-1,1))\n",
    "df['Total Time Spent on Website'] = rob_scaler.fit_transform(df['Total Time Spent on Website'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['TotalVisits'].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Converting all the categorical variables to dummy variables\n",
    "dfCat = pd.get_dummies(df[['Lead Origin','Lead Source','Do Not Email','Do Not Call','Last Activity','Search','Magazine','Newspaper Article','X Education Forums','Newspaper','Digital Advertisement','Through Recommendations','Receive More Updates About Our Courses','Update me on Supply Chain Content','Get updates on DM Content','I agree to pay the amount through cheque','A free copy of Mastering The Interview','Last Notable Activity']])\n",
    "dfCat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Seperating the numerical data\n",
    "dfNum = df[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']]\n",
    "dfNum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Merging with the original data frame\n",
    "# Preparing the X variables\n",
    "X = pd.concat([dfCat, dfNum], axis=1)\n",
    "print(X.shape)\n",
    "# Preparing the Y variable\n",
    "Y = df['Converted']\n",
    "print(Y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().values.any())\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Using train_test_split to Split Data into Training and Testing Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we build and train our Random Forest Model \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=5, random_state=42, n_estimators = 300).fit(X_train, y_train)\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(rf, X_test, y_test,\n",
    "                           n_repeats=10,\n",
    "                           random_state=0)\n",
    "perm = pd.DataFrame(columns=['AVG_Importance', 'STD_Importance'], index=[i for i in X_train.columns])\n",
    "perm['AVG_Importance'] = r.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perm.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = permutation_importance(kn, X_test, y_test, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# get importance\n",
    "importance = results.importances_mean\n",
    "importance=np.sort(importance)\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: {}  Score: {}' .format(i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))] ,importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "column_labels = X.columns.tolist()\n",
    "# coef = importance\n",
    "\n",
    "# Zip together\n",
    "labels_importance = list(zip(column_labels, importance))\n",
    "# Sort them\n",
    "labels_importance.sort(key=lambda y: y[1])\n",
    "\n",
    "# Verify the result\n",
    "# print(labels_coef)\n",
    "for x in labels_importance:\n",
    "    print(x[0], x[1])\n",
    "    # print(\"Feature : {} has score  : {} \".format(index,val))\n",
    "# for index,val in enumerate(importance):\n",
    "#    print(\"Feature : {} has score  : {} \".format(index,val))\n",
    "    \n",
    "#plotting the features and their score in ascending order\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.bar([i for i in range (len(importance))],importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient as feature importance - Logistic Regression / Linear Regression or Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X,Y)\n",
    "importance = model.coef_[0]\n",
    "importance = np.sort(importance)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,val in enumerate(importance):\n",
    "    print(\"Feature : {} has score  : {} \".format(index,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "column_labels = X.columns.tolist()\n",
    "# coef = importance\n",
    "\n",
    "# Zip together\n",
    "labels_importance = list(zip(column_labels, importance))\n",
    "# Sort them\n",
    "labels_importance.sort(key=lambda y: y[1])\n",
    "\n",
    "# Verify the result\n",
    "# print(labels_coef)\n",
    "for x in labels_importance:\n",
    "    print(x[0], x[1])\n",
    "    # print(\"Feature : {} has score  : {} \".format(index,val))\n",
    "# for index,val in enumerate(importance):\n",
    "#    print(\"Feature : {} has score  : {} \".format(index,val))\n",
    "    \n",
    "#plotting the features and their score in ascending order\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.bar([i for i in range (len(importance))],importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "model=LinearRegression()\n",
    "model.fit(X,y)\n",
    "importance=model.coef_\n",
    "importance=np.sort(importance)\n",
    "#plotting the features and their score in ascending order\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.bar([i for i in range (len(importance))],importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with Decision Trees (CARTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with the original data frame\n",
    "# Preparing the X variables\n",
    "X = pd.concat([catDF, numDF], axis=1)\n",
    "print(X.shape)\n",
    "# Preparing the Y variable\n",
    "Y = df['churn']\n",
    "print(Y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree models have trouble turning strings to float to labeling the target variable so there is a complete feature matrix\n",
    "Y = Y.replace(to_replace=['No','Yes'],value=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X,Y)\n",
    "importance = model.feature_importances_\n",
    "importance = np.sort(importance)\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: {}, Score: {}'.format(i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "column_labels = X.columns.tolist()\n",
    "# coef = importance\n",
    "\n",
    "# Zip together\n",
    "labels_importance = list(zip(column_labels, importance))\n",
    "# Sort them\n",
    "labels_importance.sort(key=lambda y: y[1])\n",
    "\n",
    "# Verify the result\n",
    "# print(labels_coef)\n",
    "for x in labels_importance:\n",
    "    print(x[0], x[1])\n",
    "    # print(\"Feature : {} has score  : {} \".format(index,val))\n",
    "# for index,val in enumerate(importance):\n",
    "#    print(\"Feature : {} has score  : {} \".format(index,val))\n",
    "    \n",
    "#plotting the features and their score in ascending order\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.bar([i for i in range (len(importance))],importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between target and features\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/datasets/main/churn.csv\")\n",
    "(df.corr().loc['churn'].plot(kind='barh', figsize=(4,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(16,10)})\n",
    "sns.heatmap(df.corr(),\n",
    "            annot=True,\n",
    "            linewidths=.5,\n",
    "            center=0,\n",
    "            cbar=False,\n",
    "            cmap=\"PiYG\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# variance of numeric features\n",
    "(df\n",
    " .select_dtypes(include=np.number)\n",
    " .var()\n",
    " .astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop uncorrelated numeric features (threshold <0.2)\n",
    "corr = abs(df.corr().loc['Converted'])\n",
    "corr = corr[corr<0.4]\n",
    "cols_to_drop = corr.index.to_list()\n",
    "df = df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
