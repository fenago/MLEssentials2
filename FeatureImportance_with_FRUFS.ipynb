{"metadata":{"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Reference: \n# --- https://github.com/atif-hassan/FRUFS\n# --- https://github.com/Vevesta/VevestaX\n!pip install FRUFS vevestaX","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"d3e34458-7906-4b8c-bd2f-06a34c8dbdf8"},{"cell_type":"code","source":"#Import libraries\nimport math\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport time\nfrom sklearn.cluster import KMeans\nfrom matplotlib.pyplot import figure\nfrom sklearn.metrics.cluster import normalized_mutual_info_score","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"09026b8a-1c12-467a-89eb-be9450ddcd3d"},{"cell_type":"code","source":"#Import FRUFS and vevestaX and create vevestaX object\nfrom FRUFS import FRUFS\nfrom vevestaX import vevesta as v\nV=v.Experiment()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"df21744f-dab6-4dd9-a74c-006db14c19f1"},{"cell_type":"code","source":"# Load the data into a dataframe (this is ML agnostic so you can use any dataset)\n# Replace with your dataset\ndf = pd.read_csv(\"https://gist.githubusercontent.com/tijptjik/9408623/raw/b237fa5848349a14a14e5d4107dc7897c21951f5/wine.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"007a6e30-244a-49fa-9cf0-f0a42250b056"},{"cell_type":"code","source":"# Split the data into input features and target variable (replace 'Wine\" with your target)\n# Replace with your target variable\ndata, Y = df.drop(['Wine'], axis=1), df['Wine'].values\n\n# Lets check out the shape of our data\nprint(\"Data shape: \", data.shape, \"Target Variable shape: \", Y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"2c5feca6-08ea-4829-90c7-bd4ac9305280"},{"cell_type":"code","source":"#extract the names of the features\nV.ds = data\n#print the names of the features\nV.ds","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"9f45cc1a-a789-4f32-b049-19b7f4af1700"},{"cell_type":"code","source":"#start the tracking scope of the variables\nV.start()\nnum_classes = 2","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"2ecfe440-c1e3-4fc1-b3d0-606af1f9cfde"},{"cell_type":"code","source":"# We want to time our algorithm\nstart = time.time()\n\nNoOfSplits = 10\nseed= 27\nshuffleFlag = True\n\n# Use KFold for understanding the performance\nkfold = KFold(n_splits=NoOfSplits, random_state=seed, shuffle=shuffleFlag)\n\n# This will hold all the accuracy scores\nscores = list()\n\n# Perform CV\nfor train, test in kfold.split(data):\n    # Split data into train and test based on folds\n    x_train, x_test = data.iloc[train], data.iloc[test]\n    y_train, y_test = Y[train], Y[test]\n    \n    # Convert the data into numpy arrays\n    x_train, x_test = x_train.values, x_test.values\n    \n    noOfFeaturesSelected=6\n    \n    # Initialize the FRUFS object with your supervised algorithm of choice\n    model = FRUFS(model_r=DecisionTreeRegressor(random_state=seed), k=noOfFeaturesSelected, n_jobs=-1, verbose=0, random_state=seed)\n \n    # Train the FRUFS model and use it to downsize your data\n    x_train = model.fit_transform(x_train)\n    x_test = model.transform(x_test)\n    \n    # Finally, classify on selected features\n    model_dt = DecisionTreeClassifier(random_state=seed)\n    model_dt.fit(x_train, y_train)\n    preds = model_dt.predict(x_test)\n\n    # We are going to use the NMI metric to measure the quality/performance of the clustering \n    score = accuracy_score(y_test, preds)\n    print(\"Score:\", score)\n    scores.append(score)\n    \n# Compute average score\naverageAccuracy = sum(scores)/len(scores)\nprint(\"\\n\\nAverage Accuracy: \", averageAccuracy)\n\n# Finally, check out the total time taken\nend = time.time()\ntimeTaken = end-start\nprint(\"\\n\\nTotal Time Required (in seconds): \", timeTaken)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"37c2208c-346c-4d43-b63c-48d819a6d520"},{"cell_type":"code","source":"#end the tracking scope of variables\nV.end()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"7f5ae31e-379c-4fc7-83fc-0490a1f8e7e6"},{"cell_type":"code","source":"figure(figsize=(8, 20), dpi=100)\nmodel.feature_importance()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"a1bd0789-e12b-477b-b891-895dfdb1b81b"},{"cell_type":"code","source":"# Download the Excel Workbook (there are MULTIPLE tabs created)\nV.dump(techniqueUsed = \"Decision tree with FRUFS\",message= \"4 selected features were used\", version=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"0f5db9e3-4ccb-48a4-86d4-7d8ab002c1da"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"52dc3a11-fa7f-4d92-9cc9-78bfd58a8700"}]}